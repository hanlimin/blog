---
title: 缓存设计
date: "2020-12-10 23:10:25"
modifyDate: "2020-12-10 23:10:25"
draft: true
---
### 缓存的收益和成本

收益如下：

- 加速读写：因为缓存通常都是在内存的，而储存层通常读写性能不够强悍，通过缓存的使用可以有效地加速读写，优化用户体验。
- 降低后端负载：帮助后端减少访问量和复杂计算，在很大程度上降低了后端负载。

成本如下：

- 数据不一致：缓存层和储存层的数据存在着一定时间窗口的不一致性，时间窗口跟更新策略有关。
- 代码维护成本：加入缓存后，需要同时处理缓存层和储存层逻辑，增大了开发者维护代码的成本。
- 运维成本：以Redis Cluster为例，加入后无形中增加了运维成本。

### 缓存更新策略

| 策略         | 一致性 | 维护成本 |
| ------------ | ------ | -------- |
| LRU/LRF/FIFU | 最差   | 低       |
| 超时剔除     | 较差   | 较低     |
| 主动更新     | 强     | 高       |

缓存中的数据通常都是有生命周期的，需要在指定时间后被删除或更新，这样可以保证缓存空间在一个可控的范围。但是缓存中的数据会和数据源的真实数据有一定时间窗口的不一致，需要利用某些策略进行更新。下面将分别从使用场景、一致性、开发人员开发/维护成本三个方面介绍三种缓存的更新策略。

1. LRU/LFU/FIFU算法剔除

    使用场景。剔除算法通常用于缓存使用量超过了预设的最大值的时候，如何对现有的数据进行剔除。例如Redis使用maxmemory-policy这个配置作为内存最大值后对于数据的剔除策略。

    一致性。要清理哪些数据是由具体算法决定，开发人员只能决定使用哪种算法，所有数据一致性是最差的。

    维护成本。算法不需要开发人员自己来实现，通常只需要配置最大maxmemory和对应的策略即可。开发人员只需要知道每种算法的含义，选择合适自己的算法即可。

2. 超时剔除

    使用场景。超时剔除通过给缓存数据设置过期时间，让其在过期时间后自动删除，例如Redis提供的expire命令。如果业务可以容忍一定时间内，缓存层和储存层数据不一致，那么可以为其设置过期时间。在数据过期后，再从真实真实数据源获取数据，重新放到缓存并设置过期时间。

    一致性。一段时间窗口内存在一致性问题，即缓存数据和真实数据源的数据不一致。

    维护成本。维护成本不是很高，只需配置expire过期时间即可，当然前提是应用方允许这段时间内数据可能发生的数据不一致。

3. 主动更新

    使用场景。应用方对于数据的一致性要求高，需要在真实数据更新后，立即更新缓存数据。例如可以利用消息系统或者其它方式通知缓存更新。

    一致性。一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超时剔除一起使用效果会更好。

    维护成本。维护成本会比较高，开发人员需要自己来完成更新，并保证更新操作的正确性。

最佳实践

有两个建议：

- 低一致性业务建议配置最大内存和淘汰策略的方式使用。

- 高一致性业务可以结合使用超时剔除和主动更新，这样即使主动更新出了问题，也能保证数据过期时间后删除脏数据。

### 缓存颗粒控制

通用性。缓存全部数据比部分数据更加通用，但从实际经验来看，很长时间内应用只需要几个重要的属性。

空间占用。缓存全部数据要比部分数据占用更多的空间，可能存在以下问题：

- 全部数据会造成内存的浪费。
- 全部数据可能每次传输产生的网络流量比较大，耗时相对较大，在极端情况下会阻塞网络。
- 全部数据的序列化和反序列化的CPU开销比较大。

代码维护。全部数据的优势更加明显，而部分数据一旦要加新字段需要修改业务代码，而且修改后通常还需要刷新缓存数据。

缓存颗粒问题是一个容易被忽视的问题，如果使用不当，可能造成很多无用空间的浪费，网络带宽的浪费，代码通用性较差等情况，需要综合数据通用性、空间占用比、代码维护性三点进行取舍。

### 穿透优化

缓存穿透是指查询一个根本不存在的数据，缓存层和储存层都不会命中，通常出于容错的考虑，如果从储存层查不到数据则不写入缓存层。整个过程如下：

1）缓存层不命中。

2）储存层不命中，不将空结果写回缓存。

3）返回空结果。

缓存穿透问题可能会使后端储存负载加大，由于很多后端储存不具备高并发性，甚至可能造成后端储存宕掉。通常可以在程序中分别统计总调用数、缓存层命中数、储存层命中数，如果发现大量储存层空命令中，可能就是出现了缓存穿透问题。造成缓存穿透的基本原因有两个。第一，自身业务代码或数据出现问题，第二，一些恶意工具、爬虫等造成大量空命中。

#### 缓存空对象

当第二步储存层不命中后，将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取数据，这样就保护了后端数据源。

缓存空对象会有两个问题：第一，空值做了缓存，意味着缓存层存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动删除。第二，缓存层和储存层的数据会有一段时间窗口的不一致，可能对业务有一定影响。

#### 布隆过滤器拦截

在访问缓存层和储存层之前，将存在的key用布隆过滤器提前保存起来，做第一层拦截。这种方法使用于数据命中不高、数据相对固定、实时性低的应用场景，代码维护较复杂，但是缓存空间占用小。

### 无底洞优化

无底洞是指在添加节点时无法带来更高的性能的现象。键值数据库由于通常采用哈希函数将key映射到多个节点上，造成key的分布与业务无关，但是由于数据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的节点上，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉及一次网络操作，分布式批量操作会涉及多次网络时间。

#### 串行命令

由于n个key时比较均匀地分布在Redis Cluster的各个节点上，因此无法使用mget命令一次性获取，所有通常来讲获取n个key的值，最简单的方法就是逐次执行n个get命令，这种操作时间复杂度较高，它的操作时间=n次网络时间+n次命令时间，网络次数是n，很明显这种方案不是最优的，但是实现起来比较简单。

#### 串行IO

Redis Cluster使用CRC16算法计算出散列值，再取对16384的余数就可以算出slot值，同时Smart客户端会保存solt和节点的对应关系，有了这两个数据就可以将属于同一个节点的key进行归档，得到每个节点的key子列表，之后对每个节点执行mget或者pipeline操作，它的操作时间=node次网络事件+n次命令时间，网络次数就是node的个数，很明显这种方案比第一种好很多，但是如果节点数太多，还是有一定的性能问题。

#### 并行IO

此方案是将方案2的最后一步改为多线程执行，网络次数虽然还是节点个数，但由于使用多线程网络时间变为O(1)，这种方案会增加编程复杂度。它的操作时间=max_slow(node网络时间)+n次命令时间。

#### hash_tag实现

可以使用Redis Cluster的hash_tag功能，它可以将多个key强制分配到一个节点上，它的操作时间=2次网络时间+n次命令时间。

### 雪崩优化

由于缓存层承载了大量请求，有效保护了储存层，但是如果缓存层由于某些原因不饿能提供服务，于是所有请求到会到达储存层，储存层的调用量会暴增，造成储存层也会级联宕机的情况。

预防和解决缓存雪崩问题。可以从以下三个方面入手。

1. 保证缓存层服务高可用性。将缓存层设计为高可用的，即使个别节点、个别机器、甚至是机房宕掉，依然可以提供服务。
2. 依赖隔离组件作为后端限流并降级。无论是缓存层还是储存层都会有出错的问题，可以将它们视同为资源。作为并发量较大的系统，假如有一个资源不可用，可能会造成线程全部阻塞在这个资源上，造成整个系统不可用。降级机制在高并发系统中是非常普遍的：比如推荐系统中，如果个性化推荐服务不可用，可以降级补充热点数据，不至于造成前端页面是开天窗。在实际项目中，我们需要对总要的资源都进行隔离，让每种资源都运行在自己的线程池中，即使个别资源出现了问题，对其它服务没有影响。但是线程池如何管理，比如如何关闭资源池、开启资源池、资源池阈值管理，这些做起来还是相当复杂，这些都可以通过使用成熟的工具来简化。比如Java依赖隔离工具Hystrix。

3. 提前演练。项目上线前，演练缓存层宕掉后，应用以及后端的负载情况以及可能出现的问题，在此基础上做一些预案设定。

### 热点key重建优化

开发人员使用缓存+过期时间的策略既可以加速数据读写，又保证数据的定期更新，这种模式基本能满足绝大部分需求。但是有两个问题如果同时出现，可能会对应用造成致命的危害：

- 当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大
- 重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的SQL、多次IO、多个依赖等。

在缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能导致让应用崩溃。要解决这个问题不是很复杂，但是不能给系统带来更多的麻烦，所以需要制定如下目标：

- 减少重建缓存的次数。
- 数据尽可能一致。
- 较少的潜在危险。

方法如下：

1. 互斥锁

    此方法只允许一个线程重建缓存，其它线程等待重建缓存的线程执行完，重新从缓存获取数据即可。

2. 永远不过期

    这里包含两种含义：

    - 从缓存层面来看，确实没有设置过期时间，所有不会出现热点key过期后产生的问题。
    - 从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独的线程去构建缓存。

    从实战来看，此方法有效杜绝了热点key产生的问题，但唯一不足的就是重建缓存期间，会出现数据不一致的情况，这取决于应用方是否容忍这种不一致。
