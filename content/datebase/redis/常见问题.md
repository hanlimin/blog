---
title: 常见问题
date: "2020-12-10 23:10:25"
modifyDate: "2020-12-10 23:10:25"
draft: true
---
### 复制

- 读写分离

    - 数据延迟

        延迟由于异步复制特性是无法避免的，延迟取决于网络带宽和命令阻塞情况。

    - 读到过期数据

        为了保证复制的一致性，从节点自身永远不会主动删除超时数据。当主节点储存大量设置超时数据时，Redis内部需要维护过期数据删除，删除策略著有有两种：惰性删除和定时删除。惰性删除：主节点每次处理读取命令时，都会检查键是否过期，如果超时则执行del命令删除键对象，之后del命令也会异步发送给从节点。定时删除：Redis主节点在内部定时任务会循环采样一定数量的键，当发现采样的键过期时执行del，之后再同步给从节点。如果有大量数据超时，主节点采样速度跟不上过期速度且主节点没有读取过期键的操作，那么从节点将无法收到del命令，这时在从节点上可以读取到已经超时的数据。

    - 从节点故障

        对于从节点故障问题，需要在客户端维护可用从节点列表，当从节点故障时立刻切换到其它从节点或主节点。

- 主从配置不一致

    内存相关的配置必须要一致。不同的内存配置可能导致从节点内存占用过大导致数据丢失。

- 规避全量复制

    - 第一次建立复制

    - 节点运行ID匹配

        当主从复制关系建立后，从节点会保存主节点的运行ID，如果此时主节点因故障重启，那么它的运行ID会改变，从节点发现主节点运行ID不匹配时，会认为自己复制的时一个新的节点从而进行全量复制。当主节点发生故障后，手动提升从节点位主节点或者采用支持自动故障转移的哨兵或集群方案。

    - 复制积压缓冲区不足

        当主从节点网络中断后，从节点再次连接上主节点时会发送psync {runId} {offset}命令请求部分复制，如果此时请求的偏移量不在主节点的积压缓冲区，则无法提供给从节点数据，因此部分复制会退化为全量复制。若网络中断时长为分钟级（net_break_time）。写命令数据可以统计高峰期主节点每秒info replication的master_repl_offset差值获取（write_size_per_minte）。积压缓冲区默认为1MB，对于大数据量场景显然不够，这时需要增大积压缓冲区，保证repl_backlog_size > net_break_time * wriet_size_per_minute，从而避免因积压缓冲区不足导致的全量复制。

- 规避复制风暴

    复制风暴是指大量从节点对同一主节点或者对同一台机器上的多个主节点短时间内发起全量复制的过程。复制风暴对发起复制的主节点或机器造成大量开销，导致CPU、内存、带宽消耗。

    - 单主节点复制风暴

        规避方案首先减少主节点挂载从节点的数量或者采用树状复制结构，加入中间层用来保护主节点。

    - 单机器复制风暴

        规避方案：1）应该把主节点尽量分散到多台机器上，避免在单台机器上部署过多的主节点。2）当主节点所在机器故障后提供故障转移机制，避免机器恢复后进行密集的全量复制。

### 阻塞

Redis是典型的单线程架构，所有的读写操作都是在一条主线程中完成。当Redis用于高并发时，如果出现阻塞，哪怕是很短的时间，对于应用来说都是严重的问题。导致阻塞问题大场景大致分为内在原因和外在原因：

1）内在原因包括：不合理地使用API或数据结构、CPU饱和、持久化阻塞等。

2）外在原因包括：CPU竞争、内存交换、网络问题等。



当Redis阻塞时，线上应用服务应该最先感应到，这时应用方会收到大量Redis超时异常。

解决方法是在应用放加入异常统计并通过邮件/短信/微信报警，以便及时发现通知问题。除此之外，还可以借助Redis监控系统发现阻塞问题，当监控系统检测到Redis运行期的一些关键指标出现不正常时会触发报警。监控系统所监控的关键指标有很多，如命令耗时、慢查询、持久化阻塞、连接拒绝、CPU/内存/网络/磁盘使用过载等。

#### 内在原因

##### API或数据结构使用不合理

通常Redis执行命令速度非常快，但也存在例外，如多一个包含上万个元素的hash结构执行hgetall操作，由于数据量比较大且命令算法复杂度时O(n)，这条命令执行速度必然很慢。这个问题就是典型的不合理使用API和数据结构。对于高并发的场景应当尽量避免在大对象上执行算法复杂度超过O(n)的命令。

解决方案为两个方案：1）修改使用的命令为低复杂度命令。2）缩减大对象数据或把大对象拆分为小对象，防止一次命令操作过多的数据。可以通过slowlog get {n}查出慢查询命令，通过redis-cli -h {ip} -p {port} --bigkeys查出大对象。

##### CPU饱和

单线程的Redis处理命令时只能使用一个CPU。而CPU饱和是指Redis把单核CPU使用率跑到接近100%。使用top命令很容易识别出Redis进程的CPU使用率。CPU饱和是非常危险的，将导致Redis无法处理更多的命令，严重影响吞吐量和应用的稳定性。

首先通过redis-cli -h {ip} -p{port} --stat来获取当前Redis使用情况，判断是否是Redis的并发量已达到极限。如果已达到并发极限，应当做集群化水平扩展来分摊QPS压力。如果没有就说明CPU饱和很不正常，有可能是使用了搞算法复杂度的命令，或者是过度的内存优化，要通过info commandstats统计信息分析出命令不合理的开销时间。

##### 持久化阻塞

对于开启了持久化功能的Redis，需要排查是否是持久化导致的阻塞。持久化引起主线程阻塞的操作有：fork阻塞、AOF刷盘阻塞、HugePage写操作阻塞。

###### fork阻塞

fork操作发生在RDB和AOF重写时，Redis主线程调用fork操作产生共享内存的子进程，由子进程完成持久化文件重写工作。如果fork操作本身耗时过长，必然会导致主线程的阻塞。可以执行info stats命令获取lastest_fork_usec指标，表示Redis最近一次fork操作耗时，如果耗时过大，比如超过1秒，则需要做出优化调整。

改善fork操作方法：

1）优先使用物理机或高效支持fork操作的虚拟化技术，避免使用Xen。

2）控制Redis实例最大可用内存，fork耗时跟内存用量成正比。

3）合理配置Linux分配策略，避免物理内存不足导致fork失败。

4）降低for操作频率，如适度放宽AOF自动触发时机，避免不必要的全量复制。

###### AOF刷盘阻塞

当开启AOF持久化功能时，文件刷盘方式一般采用每秒一次，后台线程每秒对AOF文件做fsync操作。当硬盘压力过大时，fsync操作需要等待，直到写入完成。如果主线程发现距离上一次fsync操作成功超过2秒，为了数据安全性它会阻塞直到后台线程执行fsync操作完成。

硬盘开销优化方法：

1）不要和其它硬盘高负载的服务部署在一起。

2）AOF重写时会消耗大量硬盘IO，可以配置no-appendfsync-on-rewrite，默认关闭，表示在AOF重写期间不做fsync操作。

3）当开启AOF功能的Redis用于高流量写入场景时，如果使用普通机械硬盘，写入吞吐一般在100MB/s左右，这时Redis实例的瓶颈主要在AOF同步硬盘上。

4）对于单机配置多个Redis实例的情况，可以配置不通实例分盘储存AOF文件，分摊硬盘写入压力。

#### 外在原因

##### CPU竞争

###### 进程竞争

Redis是典型的CPU密集型应用，不建议和其它多核CPU密集性服务部署在一起。当其他进程过度消耗CPU时，将严重影响Redis吞吐量。

###### 绑定CPU

部署Redis时为了充分利用多核CPU，通常一台服务器部署多个实例。常见的一种优化是把Redis进程绑定CPU上，用于降低CPU频繁上下文切换的开销。这个优化技巧正常情况下没有问题，但是当Redis父进程创建子进程进行RDB/AOF重写时，如果做了CPU绑定，会与父进程共享使用一个CPU。子进程重写时对单核CPU使用率通常在90%以上，父进程和子进程将产生激烈的CPU竞争，极大影响Redis稳定性。

##### 内存交换

内存交换对于Redis来说是非常致命的，Redis保证高性能的一个前提是所有数据在内存中。如果操作系统把Redis使用的部分内存换出到硬盘，由于内存和硬盘读写速度差几个数量级，会导致发生交换后的Redis性能急剧下降。

可以通过Redis进程号查看内存交换信息。

预防内存交换的方法：

1）保证机器充足的可以内存。

2）确保所有Redis实例设置最大可用内存，防止极端情况下Redis内存不可控的增长。

3）降低系统使用swap优先级。

##### 网络问题

网路问题经常引起Redi阻塞的问题点。常见的网络问题主要有：连接拒绝、网络延迟、网络软中断等。

###### 连接拒绝

- 网络闪断

    一般发生在在网络割接或者带宽耗尽的情况，对于网络闪断的识别比较困难，常见的作法可以通过sar -n DEV查看本机历史流量是否正确，或者借助外部系统监控工具进行识别。具体问题定位需要更上层的运维支持，对于重要的Redis服务需要充分考虑部署架构的优化，尽量避免客户端与Redis之间异地跨机房调用。

- Redis连接拒绝

    Redis通过maxclients参数控制客户端最大连接数，默认10000。当Redis连接数大于maxclients时会拒绝新的连接进入，info stats的rejected_connection统计指标记录所有被拒绝连接的数量。Redis使用多路复用IO模型可支撑大量连接，但是不代表可以无限连接。客户端访问Redis时尽量采用NIO长连接或者连接池方式。

- 连接溢出

    这是指操作系统或者Redis客户端在连接时的问题。这个问题的原因比较多，这里只介绍两种语原因：

    1）进程限制，操作系统一般会对进程使用的资源做限制，其中一项是对进程可打开最大文件数控制，通过ulimit -u 查看，通常默认1024。由于Linux系统对TCP连接也定义为一个文件句柄，因此对于支撑大量连接的Redis来说需要增大这个值，如设置unlimit -n 65535。

    2）backlog队列溢出，系统对于特定端口的TCP连接使用backlog队列保存。Redis默认的长度为511，通过tcp-backlog参数设置。如果Redis用于高并发场景为了防止缓慢连接占用，可适当增大这个设置，但必须大于操作系统允许值才能生效。系统的backlog默认值为128，可以通过命令修改。

###### 网络延迟

网络延迟取决于客户端到Redis服务器之间的网络环境。主要包括它们之间的物理拓扑和带宽占用情况。常见的物理拓扑按网络延迟由快到慢可分为：同物理机 > 同机架 > 跨机架 > 同机房 > 同城机房 > 异地机房。当它们的容灾性正好相反，同物理机最低而异地机房容灾最高。Redis提供了测量机器之间网络延迟的工具。网路延迟问题经常出现在跨机房的部署结构上，对于机房之间延迟比较严重的场景需要调整拓扑结构。

带宽瓶颈通常出现在以下几个方面：

- 机器网卡带宽。
- 机架交换机带宽。
- 机房之间专线带宽。

带宽占用主要根据当时使用率是否达到瓶颈有关，如频繁操作Redis的大对象对于千兆网卡的机器很容易达到网卡瓶颈，因此需要重点监控机器流量，及时发现网卡打满产生的网络延迟或通信中断等情况，而机房专线和交换机带宽一般由上层运维监控支持，通常出现瓶颈的概率较小。

###### 网卡软中断

网卡软中断是指由于单个网卡队列只能使用一个CPU，高并发下网卡数据交换都集中在同一个CPU，导致无法充分利用多核CPU的情况。可以通过设置中断亲缘性和Redis进程亲缘性解决。

### 集群运维

#### 集群完整性

为了保证集群完整性，默认情况下当集群16384个槽任何一个没有指派到节点时整个集群不可用。执行任何键命令返回（error）CLUSTERDOWN Hash slot not served错误。这是对集群完整性的一种保护措施，保证所有的槽都指派给在线的节点。但是持有槽的主节点下线时，从故障发现到自动完成转移期间真个集群是不可用状态，对于大多数业务无法容忍这种情况，因此建议将参数 cluster-require-full-coverage配置为no，当主节点故障时只影响它负责槽的相关命令执行，不会影响其它主节点的可用性。

#### 带宽消耗

集群内Gossip消息通信本身会消耗宽带，官方建议集群最大规模在1000以内，也是出于消息通信成本考虑，因此单集群不适合部署在超大规模的节点。

#### Pub/Sub广播问题

Redis在2.0版本提供了Pub/Sub功能，用于针对频道实时消息的发布和订阅。但是在集群模式下内部实现对所有的publish命令都会向所有节点进行广播，造成每个publish数据都会在集群内所有节点传播一次，加重宽带负担。

#### 集群倾斜

集群倾斜是指不同节点之间数据量和请求量出现明显差异，这种情况将会加大负载均衡和开发运维难度。因此需要理解哪些原因会造成集群倾斜，从而避免这个问题。

##### 数据倾斜

- 节点和槽分批严重不均。
- 不同槽对应的键数量差异过大。
- 集合对象包含大量元素。
- 内存相关配置不一致。

##### 请求倾斜

集群内特定节点请求量/流量过大导致节点之间负载不均，影响集群均衡和运维成本。常出现在热点键场景，当键命令消耗较低时如小对象的get、set、incr等，即使请求量差异较大一般也不会产生负载严重不均。但是热点键对应的高等算法复杂度的命令或者是大对象操作如hgetall、smembers等，会导致对应节点负载过高的情况。避免方式如下：

1）合理设计键，热点大集合对象做拆分或使用hmget代替hgetall避免整体读取。

2）不要使用热键作为hash_tag，避免映射到同一槽。

3）对于一致性要求不高的场景，客户端可使用本地缓存减少热键调用。



